{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation of Spacy\n",
    "\n",
    "**!pip3 install spacy**\n",
    "\n",
    "Since Spacy automatically doesn't download english version.\n",
    "\n",
    "**!python3 -m spacy download en**\n",
    "\n",
    "You can now load the model via **nlp=spacy.load('en')**\n",
    "\n",
    "# Some Tutorials\n",
    "* https://nlpforhackers.io/complete-guide-to-spacy/\n",
    "\n",
    "\n",
    "### Basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hello\" 0\n",
      "\"    \" 6\n",
      "\"World\" 10\n",
      "\"!\" 15\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp('Hello     World!')\n",
    "for token in doc:\n",
    "    print('\"' + token.text + '\"', token.idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next\t0\tnext\tFalse\tFalse\tXxxx\tADJ\tJJ\n",
      "week\t5\tweek\tFalse\tFalse\txxxx\tNOUN\tNN\n",
      "I\t10\t-PRON-\tFalse\tFalse\tX\tPRON\tPRP\n",
      "'ll\t11\twill\tFalse\tFalse\t'xx\tVERB\tMD\n",
      "  \t15\t  \tFalse\tTrue\t  \tSPACE\t_SP\n",
      "be\t17\tbe\tFalse\tFalse\txx\tAUX\tVB\n",
      "in\t20\tin\tFalse\tFalse\txx\tADP\tIN\n",
      "Madrid\t23\tMadrid\tFalse\tFalse\tXxxxx\tPROPN\tNNP\n",
      ".\t29\t.\tTrue\tFalse\t.\tPUNCT\t.\n",
      " \t31\t \tFalse\tTrue\t \tSPACE\t_SP\n",
      "Wo\t32\twill\tFalse\tFalse\tXx\tVERB\tMD\n",
      "n't\t34\tnot\tFalse\tFalse\tx'x\tPART\tRB\n",
      "I\t38\t-PRON-\tFalse\tFalse\tX\tPRON\tPRP\n",
      "?\t39\t?\tTrue\tFalse\t?\tPUNCT\t.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Next week I'll   be in Madrid.  Won't I?\")\n",
    "for token in doc:\n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
    "        token.text,\n",
    "        token.idx,\n",
    "        token.lemma_,\n",
    "        token.is_punct,\n",
    "        token.is_space,\n",
    "        token.shape_,\n",
    "        token.pos_,\n",
    "        token.tag_\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are apples.\n",
      "The webpage is www.google.com.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"These are apples. The webpage is www.google.com.\")\n",
    " \n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Of Speech Tagging\n",
    "\n",
    "Source: \n",
    "1. https://www.nltk.org/book/ch05.html\n",
    "2. https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/\n",
    "\n",
    "* CC coordinating conjunction\n",
    "* CD cardinal digit\n",
    "* DT determiner\n",
    "* EX existential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "* FW foreign word\n",
    "* IN preposition/subordinating conjunction\n",
    "* JJ adjective 'big'\n",
    "* JJR adjective, comparative 'bigger'\n",
    "* JJS adjective, superlative 'biggest'\n",
    "* LS list marker 1)\n",
    "* MD modal could, will\n",
    "* NN noun, singular 'desk'\n",
    "* NNS noun plural 'desks'\n",
    "* NNP proper noun, singular 'Harrison'\n",
    "* NNPS proper noun, plural 'Americans'\n",
    "* PDT predeterminer 'all the kids'\n",
    "* POS possessive ending parent's\n",
    "* PRP personal pronoun I, he, she\n",
    "* PRP possessive pronoun my, his, hers\n",
    "* RB adverb very, silently,\n",
    "* RBR adverb, comparative better\n",
    "* RBS adverb, superlative best\n",
    "* RP particle give up\n",
    "* TO to go 'to' the store.\n",
    "* UH interjection errrrrrrrm\n",
    "* VB verb, base form take\n",
    "* VBG verb, gerund/present participle taking\n",
    "* VBN verb, past participle taken\n",
    "* VBP verb, sing. present, non-3d take\n",
    "* VBZ verb, 3rd person sing. present takes\n",
    "* WDT wh-determiner which\n",
    "* WP wh-pronoun who, what\n",
    "* WP possessive wh-pronoun whose\n",
    "* WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Next', 'JJ'), ('week', 'NN'), ('I', 'PRP'), (\"'ll\", 'MD'), ('be', 'VB'), ('in', 'IN'), ('Madrid', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Next week I'll be in Madrid.\")\n",
    "print([(token.text, token.tag_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition And Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next week DATE\n",
      "Madrid GPE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Next week I'll be in Madrid.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank of America      ORG        \n",
      "Tech Center          ORG        \n",
      "Plano                GPE        \n",
      "$20 Million dollars  MONEY      \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Bank of America to build a Tech Center in Plano for \\\n",
    "            $20 Million dollars!!!\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ ent.text:{20}} {ent.label_:{10}} \")\n",
    "    #print(f\"{token.pos_:{10}} {token.text:{10}} {token.dep_:{10}} {token} \" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank\n",
      "America\n",
      "a Tech Center\n",
      "Plano\n",
      "$20 Million dollars\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66185343 0.23552851\n",
      "0.67148364 0.24272855\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "banana = nlp.vocab['banana']\n",
    "dog = nlp.vocab['dog']\n",
    "fruit = nlp.vocab['fruit']\n",
    "animal = nlp.vocab['animal']\n",
    " \n",
    "print(dog.similarity(animal), dog.similarity(fruit)) \n",
    "print(banana.similarity(fruit), banana.similarity(animal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x11a292f50>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x11a3af440>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x11a29d280>)]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN      Bank       nsubj      Bank \n",
      "ADP        of         prep       of \n",
      "PROPN      America    pobj       America \n",
      "AUX        is         aux        is \n",
      "VERB       looking    ROOT       looking \n",
      "PART       to         aux        to \n",
      "VERB       buy        xcomp      buy \n",
      "DET        a          det        a \n",
      "PROPN      U.S.       compound   U.S. \n",
      "NOUN       startup    dobj       startup \n",
      "ADP        for        prep       for \n",
      "NUM        6          nummod     6 \n",
      "NOUN       millions   pobj       millions \n",
      "CCONJ      and        cc         and \n",
      "VERB       sell       conj       sell \n",
      "PRON       it         dobj       it \n",
      "ADP        for        prep       for \n",
      "NUM        100        nummod     100 \n",
      "NOUN       Billions   pobj       Billions \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Bank of America is looking to buy a U.S. startup for 6 millions and sell it for 100 Billions')\n",
    "for token in doc:\n",
    "    #print(token.text, token, token.pos_)\n",
    "    print(f\"{token.pos_:{10}} {token.text:{10}} {token.dep_:{10}} {token} \" )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x11ee9e450>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x1224e8050>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x11ef51de0>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN      Tesla      nsubj      Tesla \n",
      "AUX        is         aux        is \n",
      "PART       n't        neg        n't \n",
      "VERB       looking    ROOT       looking \n",
      "ADP        into       prep       into \n",
      "SPACE                                     \n",
      "NOUN       startups   pobj       startups \n",
      "ADV        anymore    advmod     anymore \n",
      "PUNCT      .          punct      . \n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"Tesla isn't looking into         startups anymore.\")\n",
    "for token in doc2:\n",
    "    #print(token.text, token.pos_, token.dep_)\n",
    "    print(f\"{token.pos_:{10}} {token.text:{10}} {token.dep_:{10}} {token} \" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spans\n",
    "\n",
    "Large documents can be difficult to work with. A span slices the large document in of form of Doc[start:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"shifting from a strategy of case containment to slowing disease transmission and averting excess morbidity and mortality,\"\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u'Health officials in Dallas City and Los Angeles County \\\n",
    "           are signaling a change in local strategy when it comes to \\\n",
    "           coronavirus testing, recommending that doctors avoid testing \\\n",
    "           patients except in cases where a test result would \\\n",
    "           significantly change the course of treatment. A news release \\\n",
    "           from the Los Angeles Department of Public Health this week \\ \n",
    "           advised doctors not to test those experiencing only mild \\ \n",
    "           respiratory symptoms unless “a diagnostic result will change \\ \n",
    "           clinical management or inform public health response. The \\ \n",
    "           recommendation reflects a \"shifting from a strategy of case \\ \n",
    "           containment to slowing disease transmission and averting \\\n",
    "           excess morbidity and mortality,\" according to the statement. \\\n",
    "           The guidance said coronavirus testing at L.A. County public \\\n",
    "           health labs will prioritized those with symptoms, health care \\\n",
    "           workers, residents of long-term care facilities, paramedics \\\n",
    "           and other high-risk situations. Others are encouraged to \\\n",
    "           simply stay at home. At about the same time, the New York \\\n",
    "           City Department of Health directed all healthcare facilities \\\n",
    "           to immediately stop testing non-hospitalized patients for \\\n",
    "           Covid-19.')\n",
    "shift_quote = doc3[87:107]\n",
    "print (shift_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.span.Span'> <class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "print (type(shift_quote), type(doc3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "Tokens are the basic building blocks of the document object, which helps to understand the meaning of the text, which is is derived from token and shows the relationship to one to another\n",
    "\n",
    "**prefix**: char at the beginning, suffix: at the end, infix: char in between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"7f78717137d84523a1988ce1b522d9d3-0\" class=\"displacy\" width=\"890\" height=\"277.0\" direction=\"ltr\" style=\"max-width: none; height: 277.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"120\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"120\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"190\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"190\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"260\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"260\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"330\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"330\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"470\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"470\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"540\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"540\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-0\" stroke-width=\"2px\" d=\"M70,142.0 C70,72.0 180.0,72.0 180.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,144.0 L62,132.0 78,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-1\" stroke-width=\"2px\" d=\"M140,142.0 C140,107.0 175.0,107.0 175.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M140,144.0 L132,132.0 148,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-2\" stroke-width=\"2px\" d=\"M280,142.0 C280,107.0 315.0,107.0 315.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M280,144.0 L272,132.0 288,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-3\" stroke-width=\"2px\" d=\"M210,142.0 C210,72.0 320.0,72.0 320.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M320.0,144.0 L328.0,132.0 312.0,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-4\" stroke-width=\"2px\" d=\"M420,142.0 C420,72.0 530.0,72.0 530.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,144.0 L412,132.0 428,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-5\" stroke-width=\"2px\" d=\"M490,142.0 C490,107.0 525.0,107.0 525.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M490,144.0 L482,132.0 498,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-6\" stroke-width=\"2px\" d=\"M350,142.0 C350,37.0 535.0,37.0 535.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M535.0,144.0 L543.0,132.0 527.0,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-7\" stroke-width=\"2px\" d=\"M350,142.0 C350,2.0 610.0,2.0 610.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610.0,144.0 L618.0,132.0 602.0,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-8\" stroke-width=\"2px\" d=\"M700,142.0 C700,72.0 810.0,72.0 810.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,144.0 L692,132.0 708,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-9\" stroke-width=\"2px\" d=\"M770,142.0 C770,107.0 805.0,107.0 805.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,144.0 L762,132.0 778,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f78717137d84523a1988ce1b522d9d3-0-10\" stroke-width=\"2px\" d=\"M630,142.0 C630,37.0 815.0,37.0 815.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f78717137d84523a1988ce1b522d9d3-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M815.0,144.0 L823.0,132.0 807.0,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(u\"Apple is going to build a U.K. factory for $6 million.\")\n",
    "\"\"\"style -> dep syntactic dependency, ent -> entity\"\"\"\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance':70})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to build a \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " factory for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a6da7f6838144816896a717a826a8eaf-0\" class=\"displacy\" width=\"2150\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,177.0 390.0,177.0 390.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-3\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,354.0 L748.0,342.0 732.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-6\" stroke-width=\"2px\" d=\"M770,352.0 C770,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,354.0 L1278.0,342.0 1262.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-7\" stroke-width=\"2px\" d=\"M770,352.0 C770,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,177.0 1965.0,177.0 1965.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a6da7f6838144816896a717a826a8eaf-0-10\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,89.5 1970.0,89.5 1970.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a6da7f6838144816896a717a826a8eaf-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1970.0,354.0 L1978.0,342.0 1962.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_1 = nlp(u\"This is a sentence\")\n",
    "displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming \n",
    "\n",
    "\n",
    "* searching for the key word-write, it might return writes, writing, wrote, in this case, \"write\" is the stem for 'write, writing, writes...'\n",
    "* It is a method for cataloging the related words, it essentially chops off letters from end until it reaches the stem is reached. in some cases this may not handle all cases, at that point lemmatization comes into picture\n",
    "* common and effective stemming tools is Porter's Algorithms developed by Martin Porter in 1980, five phases of word reduction each with its own set of mapping rule, Snowball is the of stemming language also developed by Martin Porter, this algorithm is called **English Stemme** or**Porter2 Stemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run        run       \n",
      "runner     runner    \n",
      "running    run       \n",
      "ran        ran       \n",
      "easily     easili    \n",
      "fairly     fairli    \n",
      "fairness   fair      \n",
      "runs       run       \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "words = ['run', 'runner', 'running', 'ran', \n",
    "         'easily', 'fairly', 'fairness','runs']\n",
    "\n",
    "for word in words:\n",
    "    print (f\"{word:{10}} {p_stemmer.stem(word):{10}}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run        run       \n",
      "runner     runner    \n",
      "running    run       \n",
      "ran        ran       \n",
      "easily     easili    \n",
      "fairly     fair      \n",
      "fairness   fair      \n",
      "runs       run       \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "for word in words:\n",
    "    print (f\"{word:{10}} {s_stemmer.stem(word):{10}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "lemmatization looks beyond reduction, and consider language's full vocabulary to apply a morphological analysis to the word. Lemma of 'was' is 'be', the lemma of mice is 'mouse', lemma of meeting might be 'meet' or 'meeting depending on its use in the sentence. Spacy only has lemmatization, it doesn't have stemming like NLTK has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I          PRON                   561228191312463089 -PRON-     \n",
      "am         AUX                  10382539506755952630 be         \n",
      "a          DET                  11901859001352538922 a          \n",
      "runner     NOUN                 12640964157389618806 runner     \n",
      "running    VERB                 12767647472892411841 run        \n",
      "in         ADP                   3002984154512732771 in         \n",
      "a          DET                  11901859001352538922 a          \n",
      "race       NOUN                  8048469955494714898 race       \n",
      "because    SCONJ                16950148841647037698 because    \n",
      "             SPACE                 7059649282071487404              \n",
      "I          PRON                   561228191312463089 -PRON-     \n",
      "love       VERB                  3702023516439754181 love       \n",
      "to         PART                  3791531372978436496 to         \n",
      "run        VERB                 12767647472892411841 run        \n",
      "since      SCONJ                10066841407251338481 since      \n",
      "I          PRON                   561228191312463089 -PRON-     \n",
      "ran        VERB                 12767647472892411841 run        \n",
      "today      NOUN                 11042482332948150395 today      \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"I am a runner running in a race because \\\n",
    "            I love to run since I ran today\")\n",
    "for token in doc:\n",
    "    print (f\"{token.text:{10}} {token.pos_:{10}} {token.lemma:{30}} {token.lemma_:{10}} \")\n",
    "    #print(token.text, '\\t', token.pos_, '\\t', token.lemma, '\\t', token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "[DEFINITION]: **Stopwords** are very common words that carry no meaning or less meaning compared to other keywords.\n",
    "\n",
    "words like 'a', 'the'.. should be filter words, spacy holds 326 english stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'much', \"'m\", 'had', 'seemed', 'next', 'also', 'was', 'always', 'he', 'up', 'your', 'after', 'we', 'hundred', 'last', 'former', 'anyhow', 'there', 'whereupon', 'into', 'him', 'not', 'thru', 'per', 'sometimes', 'still', 'n‘t', 'two', 'behind', 'elsewhere', 'it', 'twenty', 'through', 'whereafter', 'moreover', 'top', 'due', 'be', 'toward', 'nobody', 'what', 'take', 'beyond', 'nine', 'very', \"n't\", 'than', 'together', 'perhaps', 'out', 'least', 'me', 'yourselves', 'among', 'from', 'part', 'meanwhile', 'four', 'nor', 'made', \"'re\", 'while', 'afterwards', 'quite', 'mostly', 'eight', 'their', 'thereafter', 'whereby', 'the', '’re', 'between', 'serious', 'others', 'whose', 'at', 'her', 'somewhere', 'or', 'various', 'i', 'but', 'empty', '‘d', 'therein', 're', 'where', 'could', 'does', 'latterly', 'whence', 'yourself', 'some', 'say', 'above', 'another', 'please', 'name', 'us', 'except', 'rather', 'own', \"'ll\", 'anyway', 'may', 'thereupon', 'more', '‘ve', 'so', 'n’t', 'give', 'because', 'whom', 'six', 'whereas', 'throughout', 'must', 'for', 'well', 'down', 'eleven', 'none', '’d', 'only', 'if', 'might', 'see', 'this', 'myself', 'forty', 'otherwise', 'that', 'fifty', 'below', '’s', 'already', 'his', 'something', 'hence', 'indeed', 'until', 'became', 'fifteen', 'am', 'themselves', 'again', 'now', 'onto', 'anywhere', 'whoever', \"'ve\", 'most', 'who', 'become', 'those', '‘re', '‘m', 'here', 'an', 'nevertheless', 'someone', 'just', 'regarding', '‘ll', 'both', 'five', 'many', 'back', 'off', 'everything', 'formerly', 'doing', 'hereafter', 'amount', 'every', 'on', 'bottom', 'do', 'hereupon', 'further', 'becomes', 'since', 'call', 'all', 'few', 'twelve', 'therefore', 'when', 'how', 'within', 'as', 'towards', 'yours', 'full', '’ve', 'they', 'whatever', 'anyone', 'noone', 'no', 'across', 'front', 'is', 'and', \"'s\", 'a', 'ca', 'although', 'whither', 'around', 'never', 'anything', 'you', 'with', 'really', 'alone', 'my', 'either', 'once', 'seem', '‘s', 'hereby', 'yet', 'go', 'sixty', 'same', 'in', 'whether', 'however', 'herself', 'ours', 'himself', 'becoming', 'whenever', 'hers', 'these', 'nowhere', 'first', 'without', \"'d\", 'cannot', 'before', 'done', 'other', 'have', 'via', 'three', 'itself', 'neither', 'though', 'ten', 'been', 'move', 'she', 'to', 'any', 'side', 'should', 'using', 'thence', 'each', 'third', 'are', 'get', 'which', 'has', 'even', 'will', 'under', 'several', 'were', 'else', 'often', 'over', 'somehow', '’m', 'one', 'thereby', 'unless', 'amongst', 'too', 'whole', 'can', 'put', 'ever', 'beforehand', 'its', 'nothing', 'why', 'thus', 'used', 'less', 'them', 'sometime', 'wherein', 'besides', 'our', 'along', 'then', 'mine', 'ourselves', 'upon', 'seeming', 'enough', 'did', 'latter', 'by', 'namely', 'beside', 'about', 'keep', 'being', 'herein', 'make', 'everyone', 'almost', 'of', 'during', '’ll', 'would', 'seems', 'against', 'everywhere', 'show', 'wherever', 'such'} 326\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words, len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.lexeme.Lexeme object at 0x147298550>\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print (nlp.vocab['is'])\n",
    "print (nlp.vocab['mystery'].is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually adding stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Defaults.stop_words.add('btw')\n",
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary and Phrase Matching with Spacy\n",
    "\n",
    "**Not VERY CLEAR TO ME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 6, 7), (8656102463236116519, 10, 13)]\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# SolarPowerΩzxzqazswsw2wasw3edxxdrdr4erdcf`\n",
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "# Solar-power\n",
    "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}]\n",
    "# Solar Power\n",
    "pattern3 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n",
    "\n",
    "matcher.add('SolarPower', None, pattern1, pattern2, pattern3 )\n",
    "doc = nlp(u\"The Solar Power continues to grow solarpower for betterment of solar-power\")\n",
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15578876784678163569 \n",
      " HelloWorld \n",
      " 0 3 Hello, world\n"
     ]
    }
   ],
   "source": [
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]\n",
    "matcher.add(\"HelloWorld\", None, pattern)\n",
    "\n",
    "doc = nlp(\"Hello, world! Hello world!\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, '\\n', string_id,'\\n', start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/gshyam/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nltk\n",
    "#nltk.download()\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I have three visions for India.', 'In 3000 years of our history, people from all over \\n               the world have come and invaded us, captured our lands, conquered our minds.', 'From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\\n               the French, the Dutch, all of them came and looted us, took over what was ours.', 'Yet we have not done this to any other nation.', 'We have not conquered anyone.', 'We have not grabbed their land, their culture, \\n               their history and tried to enforce our way of life on them.', 'Why?', 'Because we respect the freedom of others.That is why my \\n               first vision is that of freedom.', 'I believe that India got its first vision of \\n               this in 1857, when we started the War of Independence.', 'It is this freedom that\\n               we must protect and nurture and build on.', 'If we are not free, no one will respect us.', 'My second vision for India’s development.', 'For fifty years we have been a developing nation.', 'It is time we see ourselves as a developed nation.', 'We are among the top 5 nations of the world\\n               in terms of GDP.', 'We have a 10 percent growth rate in most areas.', 'Our poverty levels are falling.', 'Our achievements are being globally recognised today.', 'Yet we lack the self-confidence to\\n               see ourselves as a developed nation, self-reliant and self-assured.', 'Isn’t this incorrect?', 'I have a third vision.', 'India must stand up to the world.', 'Because I believe that unless India \\n               stands up to the world, no one will respect us.', 'Only strength respects strength.', 'We must be \\n               strong not only as a military power but also as an economic power.', 'Both must go hand-in-hand.', 'My good fortune was to have worked with three great minds.', 'Dr. Vikram Sarabhai of the Dept.', 'of \\n               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.', 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.', 'I see four milestones in my career']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\"\n",
    "\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "stemmer = PorterStemmer()\n",
    "print (sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
