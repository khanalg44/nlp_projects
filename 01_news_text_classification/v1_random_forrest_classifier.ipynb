{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# News Text Classification\n",
    "\n",
    "* News Category Dataset set from [Kaggle competition](https://www.kaggle.com/rmisra/news-category-dataset).\n",
    "* Nice [sklearn tutorial](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html).\n",
    "\n",
    "\n",
    "\n",
    "## 1. Understanding the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    " \n",
    "#this assumes one json item per line in json file\n",
    "df=pd.read_json(\"./data/news_category_dataset.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['short_description', 'headline', 'date', 'link', 'authors', 'category'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Texts for Classification\n",
    "\n",
    "These are some of the fields we can use for the classification task. We create 3 different versions.\n",
    "\n",
    "**Tokenize the Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize(url):   \n",
    "    import re\n",
    "    url=url.replace(\"https://www.huffingtonpost.com/entry/\",\"\")\n",
    "    url=re.sub(\"(\\W|_)+\",\" \",url)\n",
    "    return url\n",
    "\n",
    "df['tokenized_url']=df['link'].apply(lambda x:Tokenize(x))\n",
    "\n",
    "#just the description\n",
    "df['text_desc'] = df['short_description']\n",
    "\n",
    "#description + headline\n",
    "df['text_desc_headline'] = df['short_description'] + ' '+ df['headline']\n",
    "\n",
    "#description + headline + tokenized url\n",
    "df['text_desc_headline_url'] = df['short_description'] + ' '+ df['headline']+\" \" + df['tokenized_url']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>tokenized_url</th>\n",
       "      <th>text_desc</th>\n",
       "      <th>text_desc_headline</th>\n",
       "      <th>text_desc_headline_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>texas amanda painter mass shooting us 5b081ab4...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   short_description  \\\n",
       "0  She left her husband. He killed their children...   \n",
       "\n",
       "                                            headline       date  \\\n",
       "0  There Were 2 Mass Shootings In Texas Last Week... 2018-05-26   \n",
       "\n",
       "                                                link          authors  \\\n",
       "0  https://www.huffingtonpost.com/entry/texas-ama...  Melissa Jeltsen   \n",
       "\n",
       "  category                                      tokenized_url  \\\n",
       "0    CRIME  texas amanda painter mass shooting us 5b081ab4...   \n",
       "\n",
       "                                           text_desc  \\\n",
       "0  She left her husband. He killed their children...   \n",
       "\n",
       "                                  text_desc_headline  \\\n",
       "0  She left her husband. He killed their children...   \n",
       "\n",
       "                              text_desc_headline_url  \n",
       "0  She left her husband. He killed their children...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'texas amanda painter mass shooting us 5b081ab4e4b0802d69caad89'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_url'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Logistic Regression Model\n",
    "\n",
    "### 3.1 Extract Features, Top k prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeatures(df, field, feature):\n",
    "    # train, test, validation split (60%, 20%, 20%)\n",
    "    df_train_val, df_test  = train_test_split(df, test_size=0.2, random_state = 8848)\n",
    "    df_train    , df_valid = train_test_split(df_train_val, test_size=0.25, random_state = 8848)\n",
    "\n",
    "    \"\"\"Extract features for given field and using different methods\"\"\"\n",
    "    # otain vectorizer for different methods\n",
    "    if feature in [\"binary\", \"counts\"]:\n",
    "        binary = (feature==\"binary\")\n",
    "        vectorizer = CountVectorizer(binary=binary, max_df=0.95)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "    vectorizer.fit_transform(df_train[field].values)\n",
    "    \n",
    "    X_train = vectorizer.transform(df_train[field].values)\n",
    "    X_valid = vectorizer.transform(df_valid[field].values)\n",
    "    X_test  = vectorizer.transform( df_test[field].values)\n",
    "    \n",
    "    y_train = df_train['category'].values\n",
    "    y_test  =  df_test['category'].values\n",
    "    y_valid = df_valid['category'].values\n",
    "\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TopKPrediction(model, X, k):\n",
    "    # get probabilities for all the labels\n",
    "    probs = model.predict_proba(X) #; print (probs.shape)\n",
    "    # find the Top k values\n",
    "    # Note1: np.argsort sorts starting the smallest so pick last k values for the biggest ones\n",
    "    best_n = np.argsort(probs, axis=1)[:, -k:]\n",
    "    # Note2: we pick the last three in that order meaning the last one is the biggest one.\n",
    "    # So reverse each item so that first prediction is the top prediction\n",
    "    best_n = [ item[::-1] for item in best_n]\n",
    "    #convert the numbers to class using model.classes_\n",
    "    preds_topk = [[model.classes_[predicted_cat] for predicted_cat in prediction] for prediction in best_n]\n",
    "    return preds_topk\n",
    "\n",
    "def ComputeAccuracy(y , y_preds_topk):\n",
    "    # Check if the actual label is among the top-k prediction\n",
    "    return sum( [ y[i] in y_preds_topk[i] for i in range(len(y))]  ) / (len(y)+0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Reciprocal Rank\n",
    "\n",
    "* Here is a [nice presentation on MRR](https://dibt.unimol.it/TAinSM2012/slides/dawn.pdf). Also check my notes for more on this.\n",
    "\n",
    "* [Medium Blog](https://medium.com/swlh/rank-aware-recsys-evaluation-metrics-5191bba16832)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReciprocalRank(y_t, y_p):\n",
    "    # add index to list only if true label is in predicted label \n",
    "    y_true_pos = [(ip+1) for ip, p in enumerate(y_p) if p == y_t]\n",
    "    # find the inverse of the position if y_true in y_pred\n",
    "    if len(y_true_pos) >0:\n",
    "        return 1./(y_true_pos[0])\n",
    "    return 0.\n",
    "\n",
    "def MRR(y_true, y_pred):\n",
    "    rr_tot = 0.\n",
    "    for i in range(len(y_true)):\n",
    "        rr_tot += ReciprocalRank(y_true[i], y_pred[i])\n",
    "    mrr = rr_tot / (len(y_true)+0.)\n",
    "    return mrr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(df, field=\"text_desc\", feature=\"binary\", k=2):\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test, vectorizer = ExtractFeatures(df, field, feature)\n",
    "    log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=8848,max_iter=50)\n",
    "    model   = log_reg.fit(X_train, y_train)\n",
    "    \n",
    "    preds_top_k = TopKPrediction(model, X_train, k)\n",
    "    accuracy_train = ComputeAccuracy(y_train, preds_top_k)\n",
    "    mrr_train = MRR(y_train, preds_top_k)\n",
    "    \n",
    "    preds_top_k = TopKPrediction(model, X_valid, k)\n",
    "    accuracy_valid = ComputeAccuracy(y_valid, preds_top_k)\n",
    "    mrr_valid = MRR(y_valid, preds_top_k)\n",
    "    \n",
    "    return model, vectorizer, [accuracy_train, accuracy_valid], [mrr_train, mrr_valid]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation: only Text description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Training set: accuracy= 69.0 %,  MRR=69.0         Validation set: accuracy= 41.0 %,  MRR=41.0 \n",
      "[LibLinear]Training set: accuracy= 69.0 %,  MRR=69.0         Validation set: accuracy= 41.0 %,  MRR=41.0 \n",
      "[LibLinear]Training set: accuracy= 47.0 %,  MRR=47.0         Validation set: accuracy= 40.0 %,  MRR=40.0 \n"
     ]
    }
   ],
   "source": [
    "field=\"text_desc\"\n",
    "\n",
    "results=[]\n",
    "\n",
    "for feature in [\"binary\", \"counts\", \"tfidf\"]:\n",
    "    for k in [1]:\n",
    "        model, vectorizer, acc, mrr = TrainModel(df, field=field, feature=feature, k=k)\n",
    "        \n",
    "        print (f\"Training set: accuracy= {100*np.round(acc[0], 2)} %,  MRR={100*np.round(mrr[0], 2)} \\\n",
    "        Validation set: accuracy= {100*np.round(acc[1], 2)} %,  MRR={100*np.round(mrr[1], 2)} \")\n",
    "        results.append([field, feature, k, acc[0], acc[1], mrr[0], mrr[1] ])\n",
    "\n",
    "        #print (f\"feature: {feature} k={k} : Training set accuracy: {100*np.round(accuracy_train, 2)} % and Validation set accuracy: {100*np.round(accuracy_valid, 2)} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['text_desc', 'binary', 1, 0.687050791407198, 0.4068725498039843, 0.687050791407198, 0.4068725498039843], ['text_desc', 'counts', 1, 0.6896510340965156, 0.4060724857988639, 0.6896510340965156, 0.4060724857988639], ['text_desc', 'tfidf', 1, 0.46727027855933223, 0.3953916313305064, 0.46727027855933223, 0.3953916313305064]]\n"
     ]
    }
   ],
   "source": [
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation: Text description plus headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Training set: accuracy= 92.0 %,  MRR=92.0         Validation set: accuracy= 60.0 %,  MRR=60.0 \n",
      "[LibLinear]Training set: accuracy= 92.0 %,  MRR=92.0         Validation set: accuracy= 60.0 %,  MRR=60.0 \n",
      "[LibLinear]Training set: accuracy= 69.0 %,  MRR=69.0         Validation set: accuracy= 57.99999999999999 %,  MRR=57.99999999999999 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "field = \"text_desc_headline\"\n",
    "\n",
    "for feature in [\"binary\", \"counts\", \"tfidf\"]:\n",
    "    for k in [1]:\n",
    "        model, vectorizer, acc, mrr = TrainModel(df, field=field, feature=feature, k=k)\n",
    "        \n",
    "        print (f\"Training set: accuracy= {100*np.round(acc[0], 2)} %,  MRR={100*np.round(mrr[0], 2)} \\\n",
    "        Validation set: accuracy= {100*np.round(acc[1], 2)} %,  MRR={100*np.round(mrr[1], 2)} \")\n",
    "        results.append([field, feature, k, acc[0], acc[1], mrr[0], mrr[1] ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation: Text description plus headline plus url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Training set: accuracy= 97.0 %,  MRR=97.0         Validation set: accuracy= 63.0 %,  MRR=63.0 \n",
      "[LibLinear]Training set: accuracy= 98.0 %,  MRR=98.0         Validation set: accuracy= 64.0 %,  MRR=64.0 \n",
      "[LibLinear]Training set: accuracy= 72.0 %,  MRR=72.0         Validation set: accuracy= 62.0 %,  MRR=62.0 \n"
     ]
    }
   ],
   "source": [
    "field=\"text_desc_headline_url\"\n",
    "\n",
    "for feature in [\"binary\", \"counts\", \"tfidf\"]:\n",
    "    for k in [1]:\n",
    "        model, vectorizer, acc, mrr = TrainModel(df, field=field, feature=feature, k=k)\n",
    "        \n",
    "        print (f\"Training set: accuracy= {100*np.round(acc[0], 2)} %,  MRR={100*np.round(mrr[0], 2)} \\\n",
    "        Validation set: accuracy= {100*np.round(acc[1], 2)} %,  MRR={100*np.round(mrr[1], 2)} \")\n",
    "        results.append([field, feature, k, acc[0], acc[1], mrr[0], mrr[1] ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['text_desc', 'binary', 1, 0.687050791407198, 0.4068725498039843, 0.687050791407198, 0.4068725498039843], ['text_desc', 'counts', 1, 0.6896510340965156, 0.4060724857988639, 0.6896510340965156, 0.4060724857988639], ['text_desc', 'tfidf', 1, 0.46727027855933223, 0.3953916313305064, 0.46727027855933223, 0.3953916313305064], ['text_desc_headline', 'binary', 1, 0.919645833611137, 0.5990079206336507, 0.919645833611137, 0.5990079206336507], ['text_desc_headline', 'counts', 1, 0.9237262144466817, 0.5970077606208497, 0.9237262144466817, 0.5970077606208497], ['text_desc_headline', 'tfidf', 1, 0.6850506047231075, 0.583966717337387, 0.6850506047231075, 0.583966717337387], ['text_desc_headline_url', 'binary', 1, 0.9695838278239303, 0.6279302344187535, 0.9695838278239303, 0.6279302344187535], ['text_desc_headline_url', 'counts', 1, 0.982478364647367, 0.6362108968717497, 0.982478364647367, 0.6362108968717497], ['text_desc_headline_url', 'tfidf', 1, 0.7214540023735548, 0.6205296423713897, 0.7214540023735548, 0.6205296423713897]]\n"
     ]
    }
   ],
   "source": [
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_fields</th>\n",
       "      <th>feature</th>\n",
       "      <th>top_k</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>training_mrr</th>\n",
       "      <th>validation_mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>text_desc_headline_url</td>\n",
       "      <td>counts</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982478</td>\n",
       "      <td>0.636211</td>\n",
       "      <td>0.982478</td>\n",
       "      <td>0.636211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>text_desc_headline_url</td>\n",
       "      <td>binary</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969584</td>\n",
       "      <td>0.627930</td>\n",
       "      <td>0.969584</td>\n",
       "      <td>0.627930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text_desc_headline_url</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.721454</td>\n",
       "      <td>0.620530</td>\n",
       "      <td>0.721454</td>\n",
       "      <td>0.620530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text_desc_headline</td>\n",
       "      <td>binary</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919646</td>\n",
       "      <td>0.599008</td>\n",
       "      <td>0.919646</td>\n",
       "      <td>0.599008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text_desc_headline</td>\n",
       "      <td>counts</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923726</td>\n",
       "      <td>0.597008</td>\n",
       "      <td>0.923726</td>\n",
       "      <td>0.597008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text_desc_headline</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.685051</td>\n",
       "      <td>0.583967</td>\n",
       "      <td>0.685051</td>\n",
       "      <td>0.583967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text_desc</td>\n",
       "      <td>binary</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687051</td>\n",
       "      <td>0.406873</td>\n",
       "      <td>0.687051</td>\n",
       "      <td>0.406873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text_desc</td>\n",
       "      <td>counts</td>\n",
       "      <td>1</td>\n",
       "      <td>0.689651</td>\n",
       "      <td>0.406072</td>\n",
       "      <td>0.689651</td>\n",
       "      <td>0.406072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text_desc</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.467270</td>\n",
       "      <td>0.395392</td>\n",
       "      <td>0.467270</td>\n",
       "      <td>0.395392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text_fields feature  top_k  training_accuracy  \\\n",
       "7  text_desc_headline_url  counts      1           0.982478   \n",
       "6  text_desc_headline_url  binary      1           0.969584   \n",
       "8  text_desc_headline_url   tfidf      1           0.721454   \n",
       "3      text_desc_headline  binary      1           0.919646   \n",
       "4      text_desc_headline  counts      1           0.923726   \n",
       "5      text_desc_headline   tfidf      1           0.685051   \n",
       "0               text_desc  binary      1           0.687051   \n",
       "1               text_desc  counts      1           0.689651   \n",
       "2               text_desc   tfidf      1           0.467270   \n",
       "\n",
       "   validation_accuracy  training_mrr  validation_mrr  \n",
       "7             0.636211      0.982478        0.636211  \n",
       "6             0.627930      0.969584        0.627930  \n",
       "8             0.620530      0.721454        0.620530  \n",
       "3             0.599008      0.919646        0.599008  \n",
       "4             0.597008      0.923726        0.597008  \n",
       "5             0.583967      0.685051        0.583967  \n",
       "0             0.406873      0.687051        0.406873  \n",
       "1             0.406072      0.689651        0.406072  \n",
       "2             0.395392      0.467270        0.395392  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['text_fields','feature','top_k','training_accuracy','validation_accuracy', 'training_mrr','validation_mrr'] \n",
    "df_results=pd.DataFrame(results,columns=columns)\n",
    "df_results.sort_values(by=['text_fields','validation_accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Predictions on Unseen Articles from CNN (not HuffPost our training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['POLITICS', 'ENTERTAINMENT']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.cnn.com/2019/07/19/politics/george-nader-child-porn-sex-charges/index.html\n",
    "X_features=vectorizer.transform([\"George Aref Nader, who was a key witness in special counsel Robert Mueller's Russia investigation, faces new charges of transporting a minor with intent to engage in criminal sexual activity and child pornography\"])\n",
    "TopKPrediction(model, X_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ENTERTAINMENT', 'STYLE']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.cnn.com/2019/07/18/entertainment/khloe-kardashian-true-thompson-video-trnd/index.html\n",
    "X_features=vectorizer.transform([\"True Thompson makes an adorable cameo in Khloe Kardashian's new makeup tutorial video\"])\n",
    "TopKPrediction(model, X_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ENTERTAINMENT', 'POLITICS']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.cnn.com/2019/07/12/entertainment/heidi-klum-tom-kaulitz/\n",
    "X_features=vectorizer.transform([\"Heidi Klum is apparently the latest celeb to get married and not tell us\"])\n",
    "TopKPrediction(model, X_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['POLITICS', 'BUSINESS']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.cnn.com/2019/07/19/investing/dow-stock-market-today/index.html\n",
    "X_features=vectorizer.transform([\"Stocks end lower as geopolitical fears rise. The Dow and US markets closed lower on Friday, as geopolitical worries overshadowed the hopes of interest rate cuts by the Federal Reserve.\"])\n",
    "TopKPrediction(model, X_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SCIENCE', 'HEALTHY LIVING']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.cnn.com/2019/07/19/health/astronaut-exercise-iv-faint-scn/index.html\n",
    "X_features=vectorizer.transform([\"Exercise in space keeps astronauts from fainting when they return to Earth, study says. \"])\n",
    "TopKPrediction(model, X_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "\n",
    "pkl_dir = \"./data/\"\n",
    "\n",
    "model_pkl=os.path.join(pkl_dir, \"model_LR.pkl\")\n",
    "\n",
    "vectorizer_pkl = os.path.join(pkl_dir, \"vectorizer_LR.pkl\")\n",
    "\n",
    "pickle.dump(model,open(model_pkl, 'wb'))\n",
    "pickle.dump(vectorizer,open(vectorizer_pkl,'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['POLITICS', 'THE WORLDPOST']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = pickle.load(open(model_pkl, 'rb'))\n",
    "vectorizer_loaded = pickle.load(open(vectorizer_pkl, 'rb'))\n",
    "\n",
    "X_features=vectorizer_loaded.transform([\"President Trump AND THE impeachment story !!!\"])\n",
    "TopKPrediction(model_loaded, X_features, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(df, clf, field=\"text_desc\", feature=\"binary\", k=2):\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test, vectorizer = ExtractFeatures(df, field, feature)\n",
    "    model   = clf.fit(X_train, y_train)\n",
    "    \n",
    "    preds_top_k = TopKPrediction(model, X_train, k)\n",
    "    accuracy_train = ComputeAccuracy(y_train, preds_top_k)\n",
    "    mrr_train = MRR(y_train, preds_top_k)\n",
    "    \n",
    "    preds_top_k = TopKPrediction(model, X_valid, k)\n",
    "    accuracy_valid = ComputeAccuracy(y_valid, preds_top_k)\n",
    "    mrr_valid = MRR(y_valid, preds_top_k)\n",
    "    \n",
    "    return model, vectorizer, [accuracy_train, accuracy_valid], [mrr_train, mrr_valid]\n",
    "\n",
    "\n",
    "#clf = LogisticRegression(verbose=1, solver='liblinear',random_state=8848,max_iter=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: accuracy= 87.0 %,  MRR=87.0     Validation set: accuracy= 33.0 %,  MRR=33.0 \n"
     ]
    }
   ],
   "source": [
    "field=\"text_desc_headline_url\"\n",
    "k=1;\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "model, vectorizer, acc, mrr = TrainModel(df, clf, field=field, feature=feature, k=k)\n",
    "\n",
    "print (f\"Training set: accuracy= {100*np.round(acc[0], 2)} %,  MRR={100*np.round(mrr[0], 2)} \\\n",
    "    Validation set: accuracy= {100*np.round(acc[1], 2)} %,  MRR={100*np.round(mrr[1], 2)} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future works\n",
    "* xgboost\n",
    "* May be Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
